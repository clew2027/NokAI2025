# NokAI ğŸ™ï¸ğŸŒ  
**Real-time audio calling app with multilingual live translation**

Built with SwiftUI, Agora, Node.js, WebSockets, Whisper AI, and MongoDB  
Created by [Charlotte Lew](mailto:your.email@example.com)

---

## ğŸš€ Overview

NokAI is a real-time iOS calling app that breaks language barriers by providing live transcription and translation during phone calls. Inspired by the experience of growing up in a multilingual household, this project aims to empower smoother cross-lingual communication through intuitive design and fast backend processing.

---

## ğŸ§  Core Features

- **ğŸ”Š Live Voice Calling**  
  Built with SwiftUI and Agora SDK for real-time audio streaming between users.

- **âœï¸ Whisper Transcription**  
  Streams PCM audio over WebSocket to a backend running Whisper AI for speech-to-text.

- **ğŸŒ Real-Time Translation**  
  Transcribed speech is translated using a translation API and displayed on screen.

- **ğŸ‘¥ Friend System**  
  Users can send/accept friend requests and view call history. Data is persisted in MongoDB.

- **ğŸ“± SwiftUI Interface**  
  Reactive UI built using `@State`, `@Binding`, and `NavigationStack`. UIKit elements are bridged via `UIViewRepresentable`.

---

## ğŸ—ï¸ App Architecture

### Frontend (iOS â€“ SwiftUI + Agora)
- Manages all call screens and UI logic
- Captures audio via Agora
- Displays real-time transcription and translation

### Backend (Node.js + WebSockets + Whisper)
- Receives and buffers audio from clients
- Transcribes audio via OpenAI Whisper
- Translates transcriptions and sends them back over WebSocket
- Handles user auth, friend requests, and call logs via REST API and MongoDB

---

## ğŸ” Interaction Flow

1. User initiates call â€” Agora establishes real-time audio stream.
2. Audio is streamed via WebSocket to backend.
3. Whisper transcribes and translates speech.
4. Translated messages are sent back to the peerâ€™s device and shown in UI.
5. Call metadata (participants, timestamps, duration) is saved to MongoDB.

---

## ğŸ› ï¸ Challenges & Fixes

- **WebSocket Latency**  
  *Fix:* Implemented throttling and audio batching to avoid backend overload.

- **Whisper Delay**  
  *Fix:* Reduced chunk sizes and used timestamps to limit reprocessing.

- **SwiftUIâ€“UIKit Compatibility**  
  *Fix:* Wrapped AgoraVideoCanvas using `UIViewRepresentable`.

---

## ğŸ§ª What I Learned

### SwiftUI & iOS Development
- MVVM architecture
- Advanced state management with `@State`, `@Binding`, `@EnvironmentObject`

### Backend Engineering
- Auth, user relationship modeling, and persistence with Express.js + MongoDB

### Real-Time Systems
- Low-latency audio streaming
- Asynchronous handling of WebSocket traffic and translation pipelines

---

## ğŸ“¦ Tech Stack

- **Frontend:** SwiftUI, Agora SDK  
- **Backend:** Node.js, Express.js, WebSocket  
- **AI:** Whisper AI (speech-to-text), Translation API  
- **Database:** MongoDB  
- **Others:** UIKit, UIViewRepresentable

---

## ğŸ—‚ï¸ Project Timeline  
**May 2025 â€“ July 2025**

---
## ğŸ“¬ Contact

If you have questions, feel free to reach out!  
ğŸ‘©â€ğŸ’» Charlotte Lew â€” clew27@seas.upenn.edu

---

Â© 2025 Charlotte Lew â€” Built with love and a passion for meaningful communication â¤ï¸
